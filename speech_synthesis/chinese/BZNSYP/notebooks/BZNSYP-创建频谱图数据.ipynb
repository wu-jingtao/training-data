{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BZNSYP - 创建频谱图数据.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwtqFgiEl2Rx"
      },
      "source": [
        "# BZNSYP - 创建频谱图数据\n",
        "\n",
        "音频经过以下变换：\n",
        "\n",
        "1. `sample_rate` 设置为 `22050`\n",
        "1. `win_length` 设置为 `512`\n",
        "1. `hop_length` 设置为 `128`\n",
        "1. `mel` 频谱图 `filter-bank` 设置为 `80`\n",
        "\n",
        "文本经过以下变换：\n",
        "\n",
        "1. 去除了带有儿化音的句子\n",
        "1. 给拼音添加标点符号\n",
        "1. 将拼音转换成了数字索引"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPkbJUSilf1R"
      },
      "source": [
        "import re\n",
        "import json\n",
        "import datetime\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHubkY88mOIn"
      },
      "source": [
        "## 挂载 Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQuOVVldmQ9f",
        "outputId": "f56f35ab-ea44-4a17-a7ab-ef5f47454d84"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOVMr1memSPP"
      },
      "source": [
        "## 解压数据\n",
        "\n",
        "数据来自：[标贝科技 - 中文标准女声音库](https://test.data-baker.com/#/data/index/source)\n",
        "\n",
        "这个必须得手动下载，然后再上传到 `Google Drive` 上\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf5hpktCz3Ww"
      },
      "source": [
        "!unrar x /content/drive/MyDrive/训练数据/语音/BZNSYP/BZNSYP.rar /content > unzip_log.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrvLPeb18P4i"
      },
      "source": [
        "## 读取句子数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oti1g7Iz8UJz"
      },
      "source": [
        "sentences = dict()\n",
        "\n",
        "with open('/content/ProsodyLabeling/000001-010000.txt', 'r', encoding='utf-8') as f:\n",
        "  # 用于去掉句子中的分隔符\n",
        "  regex = re.compile('#\\d')\n",
        "  \n",
        "  while True:\n",
        "    l1 = f.readline()\n",
        "    l2 = f.readline()\n",
        "    if len(l1) == 0: break\n",
        "\n",
        "    name, sentence = l1.split('\\t')\n",
        "    pinyins = l2.strip().split(' ')\n",
        "    sentence = regex.sub('', sentence.strip())\n",
        "\n",
        "    sentences[name] = {'pinyins': pinyins, 'sentence': sentence}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZHSWL9Wl59h"
      },
      "source": [
        "## 构建 5 声拼音映射字典\n",
        "\n",
        "这个里面只包含训练数据中出现过的发音，缺失的发音将用近似的发音来进行替代。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zynA6l8mPvqd"
      },
      "source": [
        "pinyin_mapper = {0: 'None', 'None': 0, 'count': 1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRYgAr9koqYE"
      },
      "source": [
        "#### 加载拼音表"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0zgvs-tosns"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/wu-jingtao/training-data/master/speech_recognition/chinese/拼音字典/phonetic.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23deIeX9ozPM"
      },
      "source": [
        "with open('phonetic.txt') as f:\n",
        "  phonetic = f.readlines()\n",
        "  phonetic = [i.strip() for i in phonetic]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjII2N9Kmlb-"
      },
      "source": [
        "#### 统计句子中出现过的发音"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdtGYGp-miWP"
      },
      "source": [
        "occurred_pinyin = set()\n",
        "\n",
        "for item in sentences.values():\n",
        "  for p in item['pinyins']:\n",
        "    occurred_pinyin.add(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXmm8nm_oCvN"
      },
      "source": [
        "#### 构建拼音字典"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYaydgj2oFns",
        "outputId": "728da638-45d4-43a5-9501-13f9a57cef34"
      },
      "source": [
        "missing_pinyin = []\n",
        "\n",
        "for i in phonetic:\n",
        "  # 查看训练数据中存在哪几种声调\n",
        "  exist = [i + str(x) in occurred_pinyin for x in range(1, 6)]\n",
        "\n",
        "  if any(exist):\n",
        "    # 确定当缺少某个声调的时候使用哪个声调来进行代替\n",
        "    base = 4 if exist[4] else\\\n",
        "          0 if exist[0] else\\\n",
        "            1 if exist[1] else\\\n",
        "              2 if exist[2] else\\\n",
        "                3 if exist[3] else -1\n",
        "    \n",
        "    base_name = i + str(base + 1)\n",
        "    pinyin_mapper[base_name] = pinyin_mapper['count']\n",
        "    pinyin_mapper[pinyin_mapper['count']] = base_name\n",
        "    pinyin_mapper['count'] += 1\n",
        "\n",
        "    for j, k in enumerate(exist):\n",
        "      if j != base:\n",
        "        name = i + str(j + 1)\n",
        "        if k:\n",
        "          pinyin_mapper[name] = pinyin_mapper['count']\n",
        "          pinyin_mapper[pinyin_mapper['count']] = name\n",
        "          pinyin_mapper['count'] += 1\n",
        "        else:\n",
        "          pinyin_mapper[name] = pinyin_mapper[base_name]\n",
        "  else:\n",
        "    missing_pinyin.append(i)\n",
        "\n",
        "print('发音类别总数：', pinyin_mapper['count'] - 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "发音类别总数： 1535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_eQT10GG6qM"
      },
      "source": [
        "#### 补全缺失的拼音"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMF6AlmP6er2"
      },
      "source": [
        "缺失的拼音"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XItQXmmvGtET",
        "outputId": "3b74d093-89ac-4a00-8025-528e3d9ab5ad"
      },
      "source": [
        "missing_pinyin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chua', 'den', 'eng', 'lue', 'm', 'nou', 'nun']"
            ]
          },
          "metadata": {},
          "execution_count": null
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIj4R2pR6hH7"
      },
      "source": [
        "要用于替代的拼音"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAsh1KBx6lRk"
      },
      "source": [
        "replace_pinyin = ['chuan', 'deng', 'neng', 'lve', 'meng', 'niu', 'nu']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76VcYXy_8akC"
      },
      "source": [
        "for missing, replace in zip(missing_pinyin, replace_pinyin):\n",
        "  for i in range(1, 6):\n",
        "    pinyin_mapper[missing + str(i)] = pinyin_mapper[replace + '5']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TVhJs0HQ2NE"
      },
      "source": [
        "#### 统计句子中出现过的标点符号"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbYXOB00Qyld",
        "outputId": "ec9d452c-9edd-45f3-f1d9-6c76a9905be7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "punctuation = set()\n",
        "\n",
        "for item in sentences.values():\n",
        "  for p in re.findall('[^ＢＰ\\u4e00-\\u9fa5]', item['sentence']):\n",
        "    punctuation.add(p)\n",
        "\n",
        "# 把句号排在最前面      \n",
        "punctuation = list(sorted(punctuation, key=lambda x: abs(ord(x) - ord('。'))))\n",
        "punctuation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['。', '、', '…', '”', '“', '—', '！', '（', '）', '，', '：', '；', '？']"
            ]
          },
          "metadata": {},
          "execution_count": null
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnssBubQ77wk"
      },
      "source": [
        "#### 添加标点符号"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ILULXmCO9Mo"
      },
      "source": [
        "# 记录不包含标点符号的类别总数\n",
        "pinyin_mapper['count_without_punctuation'] = pinyin_mapper['count']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgt7ocBp8B5s"
      },
      "source": [
        "for item in punctuation:\n",
        "  pinyin_mapper[item] = pinyin_mapper['count']\n",
        "  pinyin_mapper[pinyin_mapper['count']] = item\n",
        "  pinyin_mapper['count'] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx5seqKMa46O"
      },
      "source": [
        "## 去除包含儿化音的句子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTN-zafAbhD8",
        "outputId": "e8f2e08b-aed3-4d93-fe2a-81c409746be6"
      },
      "source": [
        "for key, value in sentences.copy().items():\n",
        "  if any([i not in pinyin_mapper for i in value['pinyins']]):\n",
        "    del sentences[key]\n",
        "\n",
        "print('不包含儿化音的句子有：', len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "不包含儿化音的句子有： 9773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46EY6vOt8wGj"
      },
      "source": [
        "## 给拼音添加标点符号"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEsMbEVu81Dt"
      },
      "source": [
        "regex = re.compile(f'[{\"\".join(punctuation)}]')\n",
        "\n",
        "for item in sentences.values():\n",
        "  start = 0\n",
        "  add_punctuation = 0\n",
        "  result = []\n",
        "  for p in regex.finditer(item['sentence']):\n",
        "    end = p.start() - add_punctuation\n",
        "    result += item['pinyins'][start:end]\n",
        "    result.append(p.group())\n",
        "    start = end\n",
        "    add_punctuation += 1\n",
        "  item['pinyins_punctuation'] = result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NNhAxD9ueDl"
      },
      "source": [
        "查看效果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk23Npm9ugp-",
        "outputId": "bb4ad33b-b652-419b-fcc9-8faee90b631e"
      },
      "source": [
        "item = sentences['002794']\n",
        "print('sentence：', item['sentence'])\n",
        "print('pinyins：', item['pinyins'])\n",
        "print('pinyins_punctuation：', item['pinyins_punctuation'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence： 海边、沙滩，还有吃海鲜呀。\n",
            "pinyins： ['hai3', 'bian1', 'sha1', 'tan1', 'hai2', 'you3', 'chi1', 'hai3', 'xian1', 'ya5']\n",
            "pinyins_punctuation： ['hai3', 'bian1', '、', 'sha1', 'tan1', '，', 'hai2', 'you3', 'chi1', 'hai3', 'xian1', 'ya5', '。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBIY47FeSmTE"
      },
      "source": [
        "添加标点符号后句子的最大长度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVaaRw1RSsTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b0f874e-0379-49b3-fd3f-a9e64831b8b7"
      },
      "source": [
        "max([len(item['pinyins_punctuation']) for item in sentences.values()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": null
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DSlXXXUsheg"
      },
      "source": [
        "## 读取音频数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGt97Db4WiE8"
      },
      "source": [
        "def load_audio_data():\n",
        "  for name in sentences.keys():\n",
        "    audio, sr = librosa.load(f'Wave/{name}.wav', sr=22050)\n",
        "    yield audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnR9oF70WvWa"
      },
      "source": [
        "audios = tf.data.Dataset.from_generator(load_audio_data, output_signature=tf.TensorSpec(shape=(None,), dtype=tf.float32))\n",
        "audios = audios.cache('audios')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRjeZmWXyoyH"
      },
      "source": [
        "## 创建频谱图"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuBlocfOutVF"
      },
      "source": [
        "def create_magnitude():\n",
        "  for wave in audios.as_numpy_iterator():\n",
        "    stft = librosa.stft(wave, n_fft=512, hop_length=128)\n",
        "    # 转换为频谱图，顺便统一音量\n",
        "    magnitude = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
        "    # 将取值范围调整到 [-1, 1] 之间\n",
        "    magnitude = (magnitude + 40) / 40\n",
        "    yield magnitude.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pmuBaNSu_LW"
      },
      "source": [
        "magnitudes = tf.data.Dataset.from_generator(create_magnitude, output_signature=tf.TensorSpec(shape=(None, 257), dtype=tf.float32))\n",
        "magnitudes = magnitudes.cache('magnitudes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw8BEGLBYS8C"
      },
      "source": [
        "## 创建 mel 频谱图"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpK_dQIpYSmZ"
      },
      "source": [
        "def create_mel():\n",
        "  for wave in audios.as_numpy_iterator():\n",
        "    S = librosa.feature.melspectrogram(wave, sr=22050, n_fft=512, hop_length=128, n_mels=80)\n",
        "    # 这里顺带做了音量统一\n",
        "    S_dB = librosa.power_to_db(S, ref=np.max) \n",
        "    # 将取值范围调整到 [-1, 1] 之间\n",
        "    S_dB = (S_dB + 40) / 40\n",
        "    yield S_dB.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHS2wum6Yd8p"
      },
      "source": [
        "mels = tf.data.Dataset.from_generator(create_mel, output_signature=tf.TensorSpec(shape=(None, 80), dtype=tf.float32))\n",
        "mels = mels.cache('mels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwafw1dlZQyx"
      },
      "source": [
        "## 保存训练数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4w8a1jd5qAh"
      },
      "source": [
        "#### 保存拼音字典"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQcf_CLm5yci"
      },
      "source": [
        "with open('pinyin_mapper.json', 'w') as f:\n",
        "  json.dump(pinyin_mapper, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIRJUvJu5p5a"
      },
      "source": [
        "#### 保存句子数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLP8gS7Y6AJr"
      },
      "source": [
        "def words_generator():\n",
        "  for item in sentences.values():\n",
        "    yield list(item['sentence'])\n",
        "\n",
        "words = tf.data.Dataset.from_generator(words_generator, output_signature=tf.TensorSpec(shape=(None,), dtype=tf.string))\n",
        "words = words.cache('words')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_TpP0PnI_Y1",
        "outputId": "5032e333-eed1-45e2-b748-a75d3ae73251"
      },
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in words: pbar.update()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9773/9773 [00:05<00:00, 1863.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD2R4t60Jb11"
      },
      "source": [
        "#### 保存拼音数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9W6fAmwJdMT"
      },
      "source": [
        "def pinyins_generator():\n",
        "  for item in sentences.values():\n",
        "    yield [pinyin_mapper[i] for i in item['pinyins']]\n",
        "\n",
        "pinyins = tf.data.Dataset.from_generator(pinyins_generator, output_signature=tf.TensorSpec(shape=(None,), dtype=tf.int32))\n",
        "pinyins = pinyins.cache('pinyins')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5MpKSkiJhJD",
        "outputId": "0d69b238-df61-4c6d-8932-534fc872ae67"
      },
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in pinyins: pbar.update()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9773/9773 [00:05<00:00, 1910.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33lelkQeJ9yJ"
      },
      "source": [
        "#### 保存带标点符号拼音数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Iy4JARXKB2r"
      },
      "source": [
        "def pinyins_punctuation_generator():\n",
        "  for item in sentences.values():\n",
        "    yield [pinyin_mapper[i] for i in item['pinyins_punctuation']]\n",
        "\n",
        "pinyins_punctuation = tf.data.Dataset.from_generator(pinyins_punctuation_generator, output_signature=tf.TensorSpec(shape=(None,), dtype=tf.int32))\n",
        "pinyins_punctuation = pinyins_punctuation.cache('/content/pinyins_punctuation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6KRh-cxKB6G",
        "outputId": "ce3e049f-df53-4db8-e8a1-f0fc24217c72"
      },
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in pinyins_punctuation: pbar.update()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9773/9773 [00:03<00:00, 2839.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWh9RIx658Zz"
      },
      "source": [
        "#### 保存音频数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaiolVGfbXXQ",
        "outputId": "b206a06e-cdc8-4691-a590-93b50cd28ad5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in audios: pbar.update()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9773/9773 [31:35<00:00,  5.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yonoXJb4-N4"
      },
      "source": [
        "#### 保存频谱图数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_iCif2ba853",
        "outputId": "addd6582-4932-4bf2-a910-51c6523f56a0"
      },
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in magnitudes: pbar.update()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9773/9773 [02:21<00:00, 68.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcdbYTgT5AkO"
      },
      "source": [
        "#### 保存 mel 频谱图数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPeK3_hS5CrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc8c934-ee91-4566-d112-83e32d197777"
      },
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in mels: pbar.update()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9773/9773 [03:21<00:00, 48.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdBaHdxKHp_M"
      },
      "source": [
        "## 创建说明文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpvTm_sYHrD8"
      },
      "source": [
        "readme = '''数据来源：https://test.data-baker.com/#/data/index/source\n",
        "项目地址：https://github.com/wu-jingtao/training-data/blob/master/speech_synthesis/chinese/BZNSYP/README.md\n",
        "创建时间：{}\n",
        "\n",
        "数据类型：\n",
        "audios：音频对应的波形图\n",
        "  {}\n",
        "\n",
        "magnitudes：音频对应的频谱图\n",
        "  {}\n",
        "\n",
        "mels：音频对应的 mel 频谱图\n",
        "  {}\n",
        "\n",
        "words：音频对应的文字\n",
        "  {}\n",
        "\n",
        "pinyins：音频对应的拼音\n",
        "  {}\n",
        "\n",
        "pinyins_punctuation：音频对应的带标点符号的拼音\n",
        "  {}\n",
        "\n",
        "示例代码：\n",
        ">>> data = tf.data.Dataset.from_generator(lambda: None, output_signature=tf.TensorSpec(shape=(None, 257), dtype=tf.float32))\n",
        ">>> data = data.cache('文件夹路径/magnitudes')\n",
        "'''\n",
        "\n",
        "readme = readme.format(\n",
        "  datetime.datetime.today(),\n",
        "  audios.element_spec,\n",
        "  magnitudes.element_spec,\n",
        "  mels.element_spec,\n",
        "  words.element_spec,\n",
        "  pinyins.element_spec,\n",
        "  pinyins_punctuation.element_spec\n",
        ")\n",
        "\n",
        "with open('README.txt', 'w') as f:\n",
        "  f.write(readme)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WrVk-xLHkW1"
      },
      "source": [
        "## 压缩数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQSGXl4HldU"
      },
      "source": [
        "!7z a BZNSYP_data.7z \\\n",
        "README.txt \\\n",
        "pinyin_mapper.json \\\n",
        "audios.index audios.data-00000-of-00001 \\\n",
        "magnitudes.index magnitudes.data-00000-of-00001 \\\n",
        "mels.index mels.data-00000-of-00001 \\\n",
        "words.index words.data-00000-of-00001 \\\n",
        "pinyins.index pinyins.data-00000-of-00001 \\\n",
        "pinyins_punctuation.index pinyins_punctuation.data-00000-of-00001 > zip_log.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfLODNKtkxxH"
      },
      "source": [
        "## 上传到 Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0n5eHScmrAr"
      },
      "source": [
        "!cp BZNSYP_data.7z /content/drive/Shareddrives/TeamDrive_top_edu/生成数据/BZNSYP_data.7z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R09DzI3RKA8i"
      },
      "source": [
        "!mkdir -p /content/drive/Shareddrives/TeamDrive_top_edu/生成数据/BZNSYP_data\n",
        "!cp \\\n",
        "README.txt \\\n",
        "pinyin_mapper.json \\\n",
        "audios.index audios.data-00000-of-00001 \\\n",
        "magnitudes.index magnitudes.data-00000-of-00001 \\\n",
        "mels.index mels.data-00000-of-00001 \\\n",
        "words.index words.data-00000-of-00001 \\\n",
        "pinyins.index pinyins.data-00000-of-00001 \\\n",
        "pinyins_punctuation.index pinyins_punctuation.data-00000-of-00001 \\\n",
        "/content/drive/Shareddrives/TeamDrive_top_edu/生成数据/BZNSYP_data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}