{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwtqFgiEl2Rx"
      },
      "source": [
        "# BZNSYP - 创建频谱图数据\n",
        "\n",
        "文本经过以下变换：\n",
        "\n",
        "1. 去除了带有儿化音的句子\n",
        "1. 给拼音添加标点符号\n",
        "1. 将拼音转换成了数字索引\n",
        "\n",
        "音频经过以下变换：\n",
        "\n",
        "1. 波形图：\n",
        "  * `sample_rate` 设置为 `22050`\n",
        "  * 音量进行了统一\n",
        "1. `mu_law` 波形图：\n",
        "  * `sample_rate` 设置为 `22050`\n",
        "  * 音量进行了统一\n",
        "  * `mu` 设置为 `255`，取值范围调整到了 `[0, 255]`\n",
        "1. `magnitude` 频谱图：\n",
        "  * `win_length` 设置为 `512`\n",
        "  * `hop_length` 设置为 `128`\n",
        "  * 取值范围调整到了 `[-1, 1]`\n",
        "1. 高分辨率 `mel` 频谱图：\n",
        "  * `win_length` 设置为 `512`\n",
        "  * `hop_length` 设置为 `128`\n",
        "  * `filter-bank` 设置为 `80`\n",
        "  * 取值范围调整到了 `[-1, 1]`\n",
        "1. 低分辨率 `mel` 频谱图：\n",
        "  * `win_length` 设置为 `2048`\n",
        "  * `hop_length` 设置为 `1024`\n",
        "  * `filter-bank` 设置为 `80`\n",
        "  * 取值范围调整到了 `[-1, 1]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPkbJUSilf1R"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import datetime\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHubkY88mOIn"
      },
      "source": [
        "## 挂载 Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQuOVVldmQ9f",
        "outputId": "174abd07-e8b5-4fe1-959e-d24d96a4fb9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOVMr1memSPP"
      },
      "source": [
        "## 解压数据\n",
        "\n",
        "数据来自：[标贝科技 - 中文标准女声音库](https://test.data-baker.com/#/data/index/source)\n",
        "\n",
        "这个必须得手动下载，然后再上传到 `Google Drive` 上\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf5hpktCz3Ww"
      },
      "outputs": [],
      "source": [
        "!unrar x /content/drive/MyDrive/训练数据/语音/BZNSYP/BZNSYP.rar /content > unzip_log.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrvLPeb18P4i"
      },
      "source": [
        "## 读取句子数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oti1g7Iz8UJz"
      },
      "outputs": [],
      "source": [
        "sentences = dict()\n",
        "\n",
        "with open('/content/ProsodyLabeling/000001-010000.txt', 'r', encoding='utf-8') as f:\n",
        "  # 用于去掉句子中的分隔符\n",
        "  regex = re.compile('#\\d')\n",
        "  \n",
        "  while True:\n",
        "    l1 = f.readline()\n",
        "    l2 = f.readline()\n",
        "    if len(l1) == 0: break\n",
        "\n",
        "    name, sentence = l1.split('\\t')\n",
        "    pinyins = l2.strip().split(' ')\n",
        "    sentence = regex.sub('', sentence.strip())\n",
        "\n",
        "    sentences[name] = {'pinyins': pinyins, 'sentence': sentence}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZHSWL9Wl59h"
      },
      "source": [
        "## 构建 5 声拼音映射字典\n",
        "\n",
        "这个里面只包含训练数据中出现过的发音，缺失的发音将用近似的发音来进行替代。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zynA6l8mPvqd"
      },
      "outputs": [],
      "source": [
        "pinyin_mapper = {0: 'None', 'None': 0, 'count': 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRYgAr9koqYE"
      },
      "source": [
        "#### 加载拼音表"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0zgvs-tosns"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/wu-jingtao/training-data/master/speech_recognition/chinese/拼音字典/phonetic.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23deIeX9ozPM"
      },
      "outputs": [],
      "source": [
        "with open('phonetic.txt') as f:\n",
        "  phonetic = f.readlines()\n",
        "  phonetic = [i.strip() for i in phonetic]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjII2N9Kmlb-"
      },
      "source": [
        "#### 统计句子中出现过的发音"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdtGYGp-miWP"
      },
      "outputs": [],
      "source": [
        "occurred_pinyin = set()\n",
        "\n",
        "for item in sentences.values():\n",
        "  for p in item['pinyins']:\n",
        "    occurred_pinyin.add(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXmm8nm_oCvN"
      },
      "source": [
        "#### 构建拼音字典"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYaydgj2oFns",
        "outputId": "e0d2e082-57b2-4037-ab72-78f336152874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "发音类别总数： 1535\n"
          ]
        }
      ],
      "source": [
        "missing_pinyin = []\n",
        "\n",
        "for i in phonetic:\n",
        "  # 查看训练数据中存在哪几种声调\n",
        "  exist = [i + str(x) in occurred_pinyin for x in range(1, 6)]\n",
        "\n",
        "  if any(exist):\n",
        "    # 确定当缺少某个声调的时候使用哪个声调来进行代替\n",
        "    base = 4 if exist[4] else\\\n",
        "          0 if exist[0] else\\\n",
        "            1 if exist[1] else\\\n",
        "              2 if exist[2] else\\\n",
        "                3 if exist[3] else -1\n",
        "    \n",
        "    base_name = i + str(base + 1)\n",
        "    pinyin_mapper[base_name] = pinyin_mapper['count']\n",
        "    pinyin_mapper[pinyin_mapper['count']] = base_name\n",
        "    pinyin_mapper['count'] += 1\n",
        "\n",
        "    for j, k in enumerate(exist):\n",
        "      if j != base:\n",
        "        name = i + str(j + 1)\n",
        "        if k:\n",
        "          pinyin_mapper[name] = pinyin_mapper['count']\n",
        "          pinyin_mapper[pinyin_mapper['count']] = name\n",
        "          pinyin_mapper['count'] += 1\n",
        "        else:\n",
        "          pinyin_mapper[name] = pinyin_mapper[base_name]\n",
        "  else:\n",
        "    missing_pinyin.append(i)\n",
        "\n",
        "print('发音类别总数：', pinyin_mapper['count'] - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_eQT10GG6qM"
      },
      "source": [
        "#### 补全缺失的拼音"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMF6AlmP6er2"
      },
      "source": [
        "缺失的拼音"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XItQXmmvGtET",
        "outputId": "f6965810-2d2d-41fc-bfce-68d498297f5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['chua', 'den', 'eng', 'lue', 'm', 'nou', 'nun']"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "missing_pinyin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIj4R2pR6hH7"
      },
      "source": [
        "要用于替代的拼音"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAsh1KBx6lRk"
      },
      "outputs": [],
      "source": [
        "replace_pinyin = ['chuan', 'deng', 'neng', 'lve', 'meng', 'niu', 'nu']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76VcYXy_8akC"
      },
      "outputs": [],
      "source": [
        "for missing, replace in zip(missing_pinyin, replace_pinyin):\n",
        "  for i in range(1, 6):\n",
        "    pinyin_mapper[missing + str(i)] = pinyin_mapper[replace + '5']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TVhJs0HQ2NE"
      },
      "source": [
        "#### 统计句子中出现过的标点符号"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbYXOB00Qyld",
        "outputId": "3f4d2dba-8cbe-41f5-9f17-2770883408cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['。', '、', '…', '”', '“', '—', '！', '（', '）', '，', '：', '；', '？']"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "punctuation = set()\n",
        "\n",
        "for item in sentences.values():\n",
        "  for p in re.findall('[^ＢＰ\\u4e00-\\u9fa5]', item['sentence']):\n",
        "    punctuation.add(p)\n",
        "\n",
        "# 把句号排在最前面      \n",
        "punctuation = list(sorted(punctuation, key=lambda x: abs(ord(x) - ord('。'))))\n",
        "punctuation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnssBubQ77wk"
      },
      "source": [
        "#### 添加标点符号"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ILULXmCO9Mo"
      },
      "outputs": [],
      "source": [
        "# 记录不包含标点符号的类别总数\n",
        "pinyin_mapper['count_without_punctuation'] = pinyin_mapper['count']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgt7ocBp8B5s"
      },
      "outputs": [],
      "source": [
        "for item in punctuation:\n",
        "  pinyin_mapper[item] = pinyin_mapper['count']\n",
        "  pinyin_mapper[pinyin_mapper['count']] = item\n",
        "  pinyin_mapper['count'] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx5seqKMa46O"
      },
      "source": [
        "## 去除包含儿化音的句子"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTN-zafAbhD8",
        "outputId": "34292522-961a-4a13-b961-d4635990a942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "不包含儿化音的句子有： 9773\n"
          ]
        }
      ],
      "source": [
        "for key, value in sentences.copy().items():\n",
        "  if any([i not in pinyin_mapper for i in value['pinyins']]):\n",
        "    del sentences[key]\n",
        "\n",
        "print('不包含儿化音的句子有：', len(sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46EY6vOt8wGj"
      },
      "source": [
        "## 给拼音添加标点符号"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEsMbEVu81Dt"
      },
      "outputs": [],
      "source": [
        "regex = re.compile(f'[{\"\".join(punctuation)}]')\n",
        "\n",
        "for item in sentences.values():\n",
        "  start = 0\n",
        "  add_punctuation = 0\n",
        "  result = []\n",
        "  for p in regex.finditer(item['sentence']):\n",
        "    end = p.start() - add_punctuation\n",
        "    result += item['pinyins'][start:end]\n",
        "    result.append(p.group())\n",
        "    start = end\n",
        "    add_punctuation += 1\n",
        "  item['pinyins_punctuation'] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NNhAxD9ueDl"
      },
      "source": [
        "查看效果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk23Npm9ugp-",
        "outputId": "88e94138-8f41-4205-bf94-4861237f5dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence： 海边、沙滩，还有吃海鲜呀。\n",
            "pinyins： ['hai3', 'bian1', 'sha1', 'tan1', 'hai2', 'you3', 'chi1', 'hai3', 'xian1', 'ya5']\n",
            "pinyins_punctuation： ['hai3', 'bian1', '、', 'sha1', 'tan1', '，', 'hai2', 'you3', 'chi1', 'hai3', 'xian1', 'ya5', '。']\n"
          ]
        }
      ],
      "source": [
        "item = sentences['002794']\n",
        "print('sentence：', item['sentence'])\n",
        "print('pinyins：', item['pinyins'])\n",
        "print('pinyins_punctuation：', item['pinyins_punctuation'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBIY47FeSmTE"
      },
      "source": [
        "添加标点符号后句子的最大长度"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVaaRw1RSsTF",
        "outputId": "59e4bcae-15c8-41c4-87fa-c66af6c54319"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max([len(item['pinyins_punctuation']) for item in sentences.values()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DSlXXXUsheg"
      },
      "source": [
        "## 读取音频数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGt97Db4WiE8"
      },
      "outputs": [],
      "source": [
        "def load_audio_data():\n",
        "  for name in sentences.keys():\n",
        "    audio, sr = librosa.load(f'Wave/{name}.wav', sr=22050)\n",
        "    audio = audio / np.max(np.abs(audio)) # 统一音量\n",
        "    yield audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnR9oF70WvWa"
      },
      "outputs": [],
      "source": [
        "audios = tf.data.Dataset.from_generator(load_audio_data, output_signature=tf.TensorSpec(shape=(None,), dtype=tf.float32))\n",
        "audios = audios.cache('audios')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAcKS3l3nF0S"
      },
      "source": [
        "## 生成 mu_law 波形图"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Br_-2HHnIE-"
      },
      "outputs": [],
      "source": [
        "def create_mu_law():\n",
        "  for wave in audios.as_numpy_iterator():\n",
        "    x = librosa.mu_compress(wave, mu=255, quantize=True)\n",
        "    x = (x + 128).astype(np.uint8)\n",
        "    yield x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXt7fEgCnUq2"
      },
      "outputs": [],
      "source": [
        "mu_law = tf.data.Dataset.from_generator(create_mu_law, output_signature=tf.TensorSpec(shape=(None,), dtype=tf.uint8))\n",
        "mu_law = mu_law.cache('mu_law')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRjeZmWXyoyH"
      },
      "source": [
        "## 创建 magnitude 频谱图"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuBlocfOutVF"
      },
      "outputs": [],
      "source": [
        "def create_magnitude():\n",
        "  for wave in audios.as_numpy_iterator():\n",
        "    stft = librosa.stft(wave, n_fft=512, hop_length=128, center=False)\n",
        "    magnitude = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
        "    magnitude = (magnitude + 40) / 40\n",
        "    yield magnitude.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pmuBaNSu_LW"
      },
      "outputs": [],
      "source": [
        "magnitudes = tf.data.Dataset.from_generator(create_magnitude, output_signature=tf.TensorSpec(shape=(None, 257), dtype=tf.float32))\n",
        "magnitudes = magnitudes.cache('magnitudes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw8BEGLBYS8C"
      },
      "source": [
        "## 创建高分辨率 mel 频谱图"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpK_dQIpYSmZ"
      },
      "outputs": [],
      "source": [
        "def create_high_mel():\n",
        "  for wave in audios.as_numpy_iterator():\n",
        "    S = librosa.feature.melspectrogram(wave, sr=22050, n_fft=512, hop_length=128, n_mels=80, center=False)\n",
        "    S_dB = librosa.power_to_db(S, ref=np.max) \n",
        "    S_dB = (S_dB + 40) / 40\n",
        "    yield S_dB.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHS2wum6Yd8p"
      },
      "outputs": [],
      "source": [
        "high_mels = tf.data.Dataset.from_generator(create_high_mel, output_signature=tf.TensorSpec(shape=(None, 80), dtype=tf.float32))\n",
        "high_mels = high_mels.cache('high_mels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUhHc1Kdoj6v"
      },
      "source": [
        "## 创建低分辨率 mel 频谱图"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhEC6_PGolgl"
      },
      "outputs": [],
      "source": [
        "def create_low_mel():\n",
        "  for wave in audios.as_numpy_iterator():\n",
        "    S = librosa.feature.melspectrogram(wave, sr=22050, n_fft=2048, hop_length=1024, n_mels=80, center=False)\n",
        "    S_dB = librosa.power_to_db(S, ref=np.max) \n",
        "    S_dB = (S_dB + 40) / 40\n",
        "    yield S_dB.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp-om-vYoldj"
      },
      "outputs": [],
      "source": [
        "low_mels = tf.data.Dataset.from_generator(create_low_mel, output_signature=tf.TensorSpec(shape=(None, 80), dtype=tf.float32))\n",
        "low_mels = low_mels.cache('low_mels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwafw1dlZQyx"
      },
      "source": [
        "## 保存训练数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4w8a1jd5qAh"
      },
      "source": [
        "#### 保存拼音字典"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQcf_CLm5yci"
      },
      "outputs": [],
      "source": [
        "with open('pinyin_mapper.json', 'w') as f:\n",
        "  json.dump(pinyin_mapper, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlBoTh2J4mbS"
      },
      "source": [
        "#### 保存句子编号"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF3VKtxa44ha"
      },
      "outputs": [],
      "source": [
        "with open('sentence_id.json', 'w') as f:\n",
        "  json.dump(list(sentences.keys()), f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIRJUvJu5p5a"
      },
      "source": [
        "#### 保存句子数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLP8gS7Y6AJr"
      },
      "outputs": [],
      "source": [
        "def words_generator():\n",
        "  for item in sentences.values():\n",
        "    yield list(item['sentence'])\n",
        "\n",
        "words = tf.data.Dataset.from_generator(words_generator, output_signature=tf.TensorSpec(shape=(None,), dtype=tf.string))\n",
        "words = words.cache('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_TpP0PnI_Y1",
        "outputId": "6b518188-5ae5-4a15-ca5a-35efe69ac124"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9773/9773 [00:05<00:00, 1835.85it/s]\n"
          ]
        }
      ],
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in words: pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD2R4t60Jb11"
      },
      "source": [
        "#### 保存拼音数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9W6fAmwJdMT"
      },
      "outputs": [],
      "source": [
        "def pinyins_generator():\n",
        "  for item in sentences.values():\n",
        "    yield [pinyin_mapper[i] for i in item['pinyins']]\n",
        "\n",
        "pinyins = tf.data.Dataset.from_generator(pinyins_generator, output_signature=tf.TensorSpec(shape=(None,), dtype=tf.int32))\n",
        "pinyins = pinyins.cache('pinyins')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5MpKSkiJhJD",
        "outputId": "2984128c-b356-432a-a8cb-ab3985ef6d83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9773/9773 [00:05<00:00, 1910.79it/s]\n"
          ]
        }
      ],
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in pinyins: pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33lelkQeJ9yJ"
      },
      "source": [
        "#### 保存带标点符号拼音数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Iy4JARXKB2r"
      },
      "outputs": [],
      "source": [
        "def pinyins_punctuation_generator():\n",
        "  for item in sentences.values():\n",
        "    yield [pinyin_mapper[i] for i in item['pinyins_punctuation']]\n",
        "\n",
        "pinyins_punctuation = tf.data.Dataset.from_generator(pinyins_punctuation_generator, output_signature=tf.TensorSpec(shape=(None,), dtype=tf.int32))\n",
        "pinyins_punctuation = pinyins_punctuation.cache('/content/pinyins_punctuation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6KRh-cxKB6G",
        "outputId": "3ff9a969-a479-4cbf-9bb2-ec2fd0cf2f6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9773/9773 [00:03<00:00, 2818.94it/s]\n"
          ]
        }
      ],
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in pinyins_punctuation: pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWh9RIx658Zz"
      },
      "source": [
        "#### 保存音频数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaiolVGfbXXQ",
        "outputId": "255bf3e2-857a-4783-988d-636a7698d223"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9773/9773 [33:32<00:00,  4.86it/s]\n"
          ]
        }
      ],
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in audios: pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oHc6QL2pLWB"
      },
      "source": [
        "#### 保存 mu_law 波形图数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOE35aDrpN9g",
        "outputId": "7d8910ec-c403-41d8-9bc6-710b4aacf546"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9773/9773 [01:31<00:00, 106.93it/s]\n"
          ]
        }
      ],
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in mu_law: pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yonoXJb4-N4"
      },
      "source": [
        "#### 保存 magnitude 频谱图数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_iCif2ba853",
        "outputId": "cc6057b0-8ff0-4d2d-c5a3-0dab6b3f6f48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9773/9773 [02:21<00:00, 68.84it/s]\n"
          ]
        }
      ],
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in magnitudes: pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB8e3LQ_pUSt"
      },
      "source": [
        "#### 保存高分辨率 mel 频谱图数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV3e6rbNpY5d",
        "outputId": "dffda4d3-ed55-441e-e73d-436cd6aec120"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9773/9773 [02:46<00:00, 58.68it/s]\n"
          ]
        }
      ],
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in high_mels: pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcdbYTgT5AkO"
      },
      "source": [
        "#### 保存低分辨率 mel 频谱图数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPeK3_hS5CrX",
        "outputId": "20c44379-0ffe-459c-e7e8-3678061db12f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9773/9773 [03:21<00:00, 48.40it/s]\n"
          ]
        }
      ],
      "source": [
        "with tqdm(total=len(sentences)) as pbar:\n",
        "  for i in low_mels: pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdBaHdxKHp_M"
      },
      "source": [
        "## 创建说明文件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpvTm_sYHrD8"
      },
      "outputs": [],
      "source": [
        "readme = '''数据来源：https://test.data-baker.com/#/data/index/source\n",
        "项目地址：https://github.com/wu-jingtao/training-data/blob/master/speech_synthesis/chinese/BZNSYP/README.md\n",
        "创建时间：{}\n",
        "音频总数：{}\n",
        "\n",
        "数据类型：\n",
        "audios：音频对应的波形图\n",
        "  {}\n",
        "\n",
        "mu_law：音频对应的 mu_law 波形图\n",
        "  {}\n",
        "\n",
        "magnitudes：音频对应的 magnitude 频谱图\n",
        "  {}\n",
        "\n",
        "high_mels：音频对应的高分辨率 mel 频谱图\n",
        "  {}\n",
        "\n",
        "low_mels：音频对应的低分辨率 mel 频谱图\n",
        "  {}\n",
        "\n",
        "words：音频对应的文字\n",
        "  {}\n",
        "\n",
        "pinyins：音频对应的拼音\n",
        "  {}\n",
        "\n",
        "pinyins_punctuation：音频对应的带标点符号的拼音\n",
        "  {}\n",
        "\n",
        "示例代码：\n",
        ">>> data = tf.data.Dataset.from_generator(lambda: None, output_signature=tf.TensorSpec(shape=(None, 257), dtype=tf.float32))\n",
        ">>> data = data.cache('文件夹路径/magnitudes')\n",
        "'''\n",
        "\n",
        "readme = readme.format(\n",
        "  datetime.datetime.today(),\n",
        "  len(sentences),\n",
        "  audios.element_spec,\n",
        "  mu_law.element_spec,\n",
        "  magnitudes.element_spec,\n",
        "  high_mels.element_spec,\n",
        "  low_mels.element_spec,\n",
        "  words.element_spec,\n",
        "  pinyins.element_spec,\n",
        "  pinyins_punctuation.element_spec\n",
        ")\n",
        "\n",
        "with open('README.txt', 'w') as f:\n",
        "  f.write(readme)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WrVk-xLHkW1"
      },
      "source": [
        "## 压缩数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHQSGXl4HldU"
      },
      "outputs": [],
      "source": [
        "!7z a BZNSYP_data.7z \\\n",
        "README.txt \\\n",
        "pinyin_mapper.json \\\n",
        "sentence_id.json \\\n",
        "audios.index audios.data-00000-of-00001 \\\n",
        "mu_law.index mu_law.data-00000-of-00001 \\\n",
        "magnitudes.index magnitudes.data-00000-of-00001 \\\n",
        "high_mels.index high_mels.data-00000-of-00001 \\\n",
        "low_mels.index low_mels.data-00000-of-00001 \\\n",
        "words.index words.data-00000-of-00001 \\\n",
        "pinyins.index pinyins.data-00000-of-00001 \\\n",
        "pinyins_punctuation.index pinyins_punctuation.data-00000-of-00001 > zip_log.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfLODNKtkxxH"
      },
      "source": [
        "## 上传到 Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0n5eHScmrAr"
      },
      "outputs": [],
      "source": [
        "!cp BZNSYP_data.7z /content/drive/Shareddrives/TeamDrive_top_edu/生成数据/BZNSYP_data.7z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R09DzI3RKA8i"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/drive/Shareddrives/TeamDrive_top_edu/生成数据/BZNSYP_data\n",
        "!cp \\\n",
        "README.txt \\\n",
        "pinyin_mapper.json \\\n",
        "sentence_id.json \\\n",
        "audios.index audios.data-00000-of-00001 \\\n",
        "mu_law.index mu_law.data-00000-of-00001 \\\n",
        "magnitudes.index magnitudes.data-00000-of-00001 \\\n",
        "high_mels.index high_mels.data-00000-of-00001 \\\n",
        "low_mels.index low_mels.data-00000-of-00001 \\\n",
        "words.index words.data-00000-of-00001 \\\n",
        "pinyins.index pinyins.data-00000-of-00001 \\\n",
        "pinyins_punctuation.index pinyins_punctuation.data-00000-of-00001 \\\n",
        "/content/drive/Shareddrives/TeamDrive_top_edu/生成数据/BZNSYP_data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "BZNSYP - 创建频谱图数据.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}